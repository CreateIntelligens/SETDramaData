#!/usr/bin/env python3
"""
UVR5 éŸ³é »å¢å¼·è™•ç†å™¨
é‡å°åˆ‡åˆ†å¾Œçš„çŸ­éŸ³æª”é€²è¡ŒéŸ³è³ªæ”¹å–„

ä¸»è¦åŠŸèƒ½ï¼š
- å–®æª”éŸ³é »å¢å¼·è™•ç†
- æ‰¹é‡ç›®éŒ„è™•ç†
- åˆ‡åˆ†è³‡æ–™é›†å¢å¼·
- è¨˜æ†¶é«”å‹å–„è¨­è¨ˆ

Author:  TTS ETL Pipeline
Version: 1.0
"""

import gc
import json
import logging
import os
import sys
import time
import traceback
import shutil
import tempfile
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import numpy as np

try:
    import torch
    import torchaudio
except ImportError:
    print("âŒ è«‹å®‰è£ PyTorch: pip install torch torchaudio")
    sys.exit(1)

try:
    from audio_separator.separator import Separator
except ImportError:
    print("âŒ è«‹å®‰è£ audio-separator: pip install 'audio-separator[gpu]'")
    sys.exit(1)

from tqdm import tqdm
import psutil


class UVR5Processor:
    """UVR5 éŸ³é »å¢å¼·è™•ç†å™¨ - å°ˆé–€è™•ç†åˆ‡åˆ†å¾Œçš„çŸ­éŸ³æª”
    
    è¨­è¨ˆåŸå‰‡ï¼š
    - è¨˜æ†¶é«”å‹å–„ï¼šå–®æª”è™•ç†é¿å…è¨˜æ†¶é«”æº¢å‡º
    - éŒ¯èª¤éš”é›¢ï¼šå–®æª”å¤±æ•—ä¸å½±éŸ¿å…¶ä»–æª”æ¡ˆ
    - é€²åº¦é€æ˜ï¼šæ¸…æ¥šé¡¯ç¤ºè™•ç†é€²åº¦å’Œç‹€æ…‹
    - é…ç½®éˆæ´»ï¼šé€éåƒæ•¸æ§åˆ¶è™•ç†è¡Œç‚º
    """
    
    def __init__(self, 
                 model_path: str = "models/uvr5",
                 vocal_model: str = "model_bs_roformer_ep_317_sdr_12.9755.ckpt",
                 device: str = "auto",
                 batch_size: int = 1,
                 min_duration: float = None,
                 target_duration: float = None,
                 processing_timeout: int = None):
        """
        åˆå§‹åŒ– UVR5 è™•ç†å™¨
        """
        self.model_path = Path(model_path)
        self.vocal_model = vocal_model
        self.batch_size = batch_size
        
        import os
        self.min_duration = min_duration if min_duration is not None else float(os.getenv('UVR5_MIN_DURATION', '10.0'))
        self.target_duration = target_duration if target_duration is not None else float(os.getenv('UVR5_TARGET_DURATION', '15.0'))
        self.processing_timeout = processing_timeout if processing_timeout is not None else int(os.getenv('UVR5_PROCESSING_TIMEOUT', '300'))
        
        self.setup_logging()
        
        # --- å»ºç«‹ä¸¦æ¸…ç†å°ˆç”¨çš„æš«å­˜ç›®éŒ„ ---
        self.temp_dir = Path.cwd() / "data" / "temp"
        self.temp_dir.mkdir(parents=True, exist_ok=True)
        self._cleanup_temp_dir(initial_cleanup=True)

        self.device = self._setup_device(device)
        self.separator = None
        self._setup_separator()
        
        self.stats = {
            'processed_files': 0,
            'failed_files': 0,
            'total_time': 0,
            'failed_list': []
        }

    def _cleanup_temp_dir(self, initial_cleanup: bool = False):
        """æ¸…ç†æš«å­˜ç›®éŒ„"""
        if initial_cleanup:
            self.logger.info(f"ğŸ§¹ æ­£åœ¨æ¸…ç†èˆŠçš„æš«å­˜æª”æ¡ˆæ–¼: {self.temp_dir}")
        
        for item in self.temp_dir.iterdir():
            try:
                if item.is_file():
                    item.unlink()
                elif item.is_dir():
                    shutil.rmtree(item)
            except Exception as e:
                self.logger.warning(f"âš ï¸ æ¸…ç†æš«å­˜é …ç›® {item} å¤±æ•—: {e}")

    def setup_logging(self):
        """è¨­å®š logging ç³»çµ±"""
        # ä½¿ç”¨æ¨¡çµ„ç´šåˆ¥çš„ loggerï¼Œæ‰€æœ‰å¯¦ä¾‹å…±äº«åŒä¸€å€‹
        logger_name = __name__
        self.logger = logging.getLogger(logger_name)
        
        # åªåœ¨ç¬¬ä¸€æ¬¡åˆå§‹åŒ–æ™‚è¨­å®š handlers
        if not hasattr(logging.getLogger(logger_name), '_uvr5_configured'):
            self.logger.setLevel(logging.DEBUG)
            self.logger.propagate = False  # é˜²æ­¢å‘ä¸Šå‚³æ’­é€ æˆé‡è¤‡è¼¸å‡º
            
            # æ¸…é™¤æ‰€æœ‰ç¾æœ‰çš„ handlers ä»¥é˜²é‡è¤‡
            self.logger.handlers.clear()
            
            # åªä½¿ç”¨ console è¼¸å‡ºï¼Œé¿å…æª”æ¡ˆæ¬Šé™å•é¡Œ
            import threading
            stream_handler = logging.StreamHandler()
            stream_handler.setFormatter(logging.Formatter('%(asctime)s - UVR5 - %(levelname)s - %(message)s'))
            self.logger.addHandler(stream_handler)
            
            # æ¨™è¨˜å·²é…ç½®ï¼Œé¿å…é‡è¤‡è¨­å®š
            logging.getLogger(logger_name)._uvr5_configured = True
    
    def _setup_device(self, device: str) -> str:
        """è¨­å®šè™•ç†è£ç½®
        
        Args:
            device (str): è£ç½®é¡å‹ ('auto', 'cuda', 'cpu')
            
        Returns:
            str: å¯¦éš›ä½¿ç”¨çš„è£ç½®é¡å‹
        """
        if device == "auto":
            if torch.cuda.is_available():
                device = "cuda"
                gpu_name = torch.cuda.get_device_name(0)
                self.logger.info(f"ğŸ® ä½¿ç”¨ GPU: {gpu_name}")
            else:
                device = "cpu"
                self.logger.info("ğŸ–¥ï¸  ä½¿ç”¨ CPU æ¨¡å¼")
        
        return device
    
    def _setup_separator(self):
        """åˆå§‹åŒ– UVR5 åˆ†é›¢å™¨"""
        try:
            # æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ
            model_file = self.model_path / self.vocal_model
            if not model_file.exists():
                raise FileNotFoundError(f"UVR5 æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_file}")
            
            # å‰µå»ºåˆ†é›¢å™¨ - é‡å°çŸ­éŸ³æª”å„ªåŒ–
            self.separator = Separator(
                log_level=logging.WARNING,  # æ¸›å°‘ UVR5 æ—¥èªŒè¼¸å‡º
                model_file_dir=str(self.model_path),
                output_dir=str(self.temp_dir),  # é è¨­ä½¿ç”¨å°ˆç”¨æš«å­˜ç›®éŒ„
                output_format='WAV',
                # é‡å°çŸ­éŸ³æª”èª¿æ•´ MDX åƒæ•¸
                mdx_params={
                    'segment_size': 128,  # è¼ƒå°çš„åˆ†æ®µé©åˆçŸ­éŸ³æª”
                    'overlap': 0.25,
                    'batch_size': 1,  # ç¢ºä¿ç©©å®šæ€§
                    'hop_length': 512   # è¼ƒå°çš„è·³èºé•·åº¦
                }
            )
            
            # è¼‰å…¥æŒ‡å®šçš„æ¨¡å‹
            self.separator.load_model(self.vocal_model)
            self.logger.info(f"âœ… UVR5 åˆ†é›¢å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"âŒ UVR5 åˆ†é›¢å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    def get_audio_duration(self, audio_path: str) -> float:
        """ç²å–éŸ³é »æª”æ¡ˆé•·åº¦ï¼ˆç§’ï¼‰
        
        Args:
            audio_path: éŸ³é »æª”æ¡ˆè·¯å¾‘
            
        Returns:
            float: éŸ³é »é•·åº¦ï¼ˆç§’ï¼‰
        """
        try:
            waveform, sample_rate = torchaudio.load(audio_path)
            duration = waveform.shape[1] / sample_rate
            return duration
        except Exception as e:
            self.logger.warning(f"âš ï¸  ç„¡æ³•ç²å–éŸ³é »é•·åº¦ {audio_path}: {e}")
            return 0.0
    
    def pad_audio_for_uvr5(self, input_path: str) -> Optional[str]:
        """ç‚ºçŸ­éŸ³é »æª”æ¡ˆé€²è¡Œè£œé›¶é è™•ç†ï¼Œä¸¦çµ±ä¸€éŸ³é »æ ¼å¼
        
        Args:
            input_path: è¼¸å…¥éŸ³é »æª”æ¡ˆè·¯å¾‘
            
        Returns:
            Optional[str]: é è™•ç†å¾Œçš„è‡¨æ™‚æª”æ¡ˆè·¯å¾‘ï¼Œå¦‚æœä¸éœ€è¦é è™•ç†å‰‡è¿”å› None
        """
        try:
            # ç²å–éŸ³é »é•·åº¦
            duration = self.get_audio_duration(input_path)
            
            if duration <= 0:
                self.logger.warning(f"âš ï¸  ç„¡æ•ˆçš„éŸ³é »æª”æ¡ˆ: {input_path}")
                return None
            
            # è¼‰å…¥éŸ³é »
            waveform, sample_rate = torchaudio.load(input_path)
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦æ ¼å¼æ¨™æº–åŒ–ï¼ˆåªä¿ç•™å¿…è¦çš„è™•ç†ï¼‰
            needs_format_fix = False
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦è£œé›¶
            needs_padding = duration < self.min_duration
            
            if needs_padding:
                self.logger.info(f"ğŸ“ éŸ³é »é•·åº¦ {duration:.2f}s < {self.min_duration}sï¼ŒåŸ·è¡Œè£œé›¶é è™•ç†...")
                
                # è¨ˆç®—éœ€è¦çš„ç¸½æ¨£æœ¬æ•¸
                target_samples = int(self.target_duration * sample_rate)
                current_samples = waveform.shape[1]
                
                if current_samples < target_samples:
                    # è¨ˆç®—éœ€è¦è£œé›¶çš„æ¨£æœ¬æ•¸
                    padding_samples = target_samples - current_samples
                    
                    # å‰å¾Œè£œé›¶ï¼ˆå¹³å‡åˆ†é…ï¼‰
                    padding_before = padding_samples // 2
                    padding_after = padding_samples - padding_before
                    
                    # å‰µå»ºè£œé›¶å¾Œçš„éŸ³é »
                    waveform = torch.nn.functional.pad(waveform, 
                                                        (padding_before, padding_after), 
                                                        'constant', 0)
            
            # å¦‚æœéœ€è¦è£œé›¶é è™•ç†ï¼Œå‰µå»ºè‡¨æ™‚æª”æ¡ˆ
            if needs_padding:
                import os
                import threading
                
                input_path_obj = Path(input_path)
                process_id = os.getpid()
                thread_id = threading.get_ident()
                timestamp = int(time.time() * 1000000)  # å¾®ç§’ç´šç²¾åº¦
                
                temp_filename = f"processed_p{process_id}_t{thread_id}_{timestamp}_{input_path_obj.name}"
                temp_path = self.temp_dir / temp_filename
                
                # ä¿å­˜é è™•ç†å¾Œçš„éŸ³é »
                torchaudio.save(str(temp_path), waveform, sample_rate)
                
                self.logger.info(f"âœ… éŸ³é »è£œé›¶å®Œæˆ: {duration:.2f}s â†’ {self.target_duration:.2f}s")
                
                return str(temp_path)
            else:
                return None  # ä¸éœ€è¦é è™•ç†
            
        except Exception as e:
            self.logger.error(f"âŒ éŸ³é »é è™•ç†å¤±æ•— {input_path}: {e}")
            return None
    
    def enhance_audio(self, input_path: str, output_path: Optional[str] = None, 
                     backup_original: any = False) -> Dict:
        """
        å°å–®å€‹éŸ³æª”é€²è¡Œ UVR5 å¢å¼·è™•ç†
        
        Args:
            input_path: è¼¸å…¥éŸ³æª”è·¯å¾‘
            output_path: è¼¸å‡ºè·¯å¾‘ (None = åŸåœ°æ›¿æ›)
            backup_original: æ˜¯å¦å‚™ä»½åŸå§‹æª”æ¡ˆ (å¯æ¥å— 'true'/'false' å­—ä¸²)
            
        Returns:
            Dict: è™•ç†çµæœ
        """
        # å°‡å‚³å…¥çš„ backup_original (å¯èƒ½ç‚ºå­—ä¸² 'true'/'false') è½‰æ›ç‚ºå¸ƒæ—å€¼
        backup_original = str(backup_original).lower() == 'true'

        input_path = Path(input_path)
        if not input_path.exists():
            raise FileNotFoundError(f"è¼¸å…¥æª”æ¡ˆä¸å­˜åœ¨: {input_path}")
        
        # æ±ºå®šè¼¸å‡ºè·¯å¾‘
        if output_path is None:
            output_path = input_path  # åŸåœ°æ›¿æ›
        else:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)
        
        result = {
            'input_file': str(input_path),
            'output_file': str(output_path),
            'success': False,
            'processing_time': 0,
            'memory_usage_mb': 0,
            'error': None,
            'enhanced': False
        }
        
        start_time = time.time()
        initial_memory = psutil.Process().memory_info().rss / (1024**2)
        
        preprocessed_file = None
        actual_input_path = input_path
        temp_output_dir = None
        
        try:
            # --- ğŸš€ å„ªå…ˆæª¢æŸ¥æ˜¯å¦å·²è™•ç†éï¼ˆçœŸæ­£å¿«é€Ÿè·³éï¼‰ ---
            if backup_original and output_path == input_path:
                backup_path = input_path.with_suffix('.bak')
                completed_backup_path = input_path.with_suffix('.bak.completed')
                
                # æª¢æŸ¥è™•ç†ç‹€æ…‹
                if completed_backup_path.exists():
                    # å·²å®Œæˆè™•ç†ï¼Œè·³é
                    result['success'] = True
                    result['enhanced'] = False
                    result['already_processed'] = True
                    result['backup_file'] = str(completed_backup_path)
                    result['processing_time'] = time.time() - start_time
                    self.logger.debug(f"â­ï¸ æª”æ¡ˆå·²è™•ç†å®Œæˆ: {input_path.name}")
                    return result
                elif backup_path.exists():
                    # æœ‰å‚™ä»½ä½†æœªå®Œæˆæ¨™è¨˜ = ä¹‹å‰è™•ç†ä¸­æ–·ï¼Œéœ€è¦æ¢å¾©
                    self.logger.warning(f"âš ï¸ ç™¼ç¾ä¸­æ–·çš„è™•ç†ï¼Œå¾å‚™ä»½æ¢å¾©: {input_path.name}")
                    
                    # åˆªé™¤å¯èƒ½æå£çš„åŸæª”æ¡ˆ
                    if input_path.exists():
                        input_path.unlink()
                    
                    # å¾å‚™ä»½æ¢å¾©åŸæª”æ¡ˆ
                    backup_path.rename(input_path)
                    
                    self.logger.info(f"âœ… å·²å¾å‚™ä»½æ¢å¾©ï¼Œé‡æ–°é–‹å§‹è™•ç†")
                    
                    # é‡ç½®å‚™ä»½è·¯å¾‘ï¼Œå¾ŒçºŒæœƒé‡æ–°å‚™ä»½
                    backup_path = input_path.with_suffix('.bak')
            
            # --- åªæœ‰æœªè™•ç†çš„æª”æ¡ˆæ‰é€²è¡ŒéŸ³æª”åˆ†æ ---
            original_duration = self.get_audio_duration(str(input_path))
            result['original_duration'] = original_duration
            
            # æ‰€æœ‰éŸ³æª”éƒ½éœ€è¦æ ¼å¼æª¢æŸ¥å’Œæ¨™æº–åŒ–ï¼ˆä¸åªæ˜¯çŸ­éŸ³æª”ï¼‰
            preprocessed_file = self.pad_audio_for_uvr5(str(input_path))
            if preprocessed_file:
                actual_input_path = Path(preprocessed_file)
                result['preprocessed'] = True
            else:
                self.logger.debug(f"â„¹ï¸  éŸ³é »ç„¡éœ€é è™•ç†: {input_path.name}")

            # å‚™ä»½åŸå§‹æª”æ¡ˆï¼ˆåªæœ‰éœ€è¦è™•ç†çš„æª”æ¡ˆæ‰å‚™ä»½ï¼‰
            if backup_original and output_path == input_path:
                backup_path = input_path.with_suffix('.bak')
                input_path.rename(backup_path)
                input_path = backup_path
                result['backup_file'] = str(backup_path)
                self.logger.info(f"ğŸ’¾ å·²å‚™ä»½åŸå§‹æª”æ¡ˆ: {backup_path.name}")
                
                # æ›´æ–°actual_input_pathï¼Œå¦‚æœä¹‹å‰æ˜¯é è™•ç†æª”æ¡ˆå‰‡ä¸è®Šï¼Œå¦å‰‡æ›´æ–°ç‚ºå‚™ä»½æª”æ¡ˆ
                if not preprocessed_file:
                    actual_input_path = backup_path

            # ä½¿ç”¨å°ˆç”¨æš«å­˜ç›®éŒ„ï¼Œé¿å…åœ¨æ ¹ç›®éŒ„ç”¢ç”Ÿæ•£è½æª”æ¡ˆ
            # ä½¿ç”¨é€²ç¨‹ID + åŸ·è¡Œç·’ID + æ™‚é–“æˆ³ + éš¨æ©Ÿæ•¸é¿å…é«˜ä¸¦ç™¼è¡çª
            import random
            import os
            import threading
            
            process_id = os.getpid()
            thread_id = threading.get_ident()
            timestamp = int(time.time() * 1000000)  # å¾®ç§’ç´šç²¾åº¦
            random_id = random.randint(1000, 9999)
            
            temp_output_dir = self.temp_dir / f"uvr5_p{process_id}_t{thread_id}_{timestamp}_{random_id}"
            temp_output_dir.mkdir(parents=True, exist_ok=True)
            
            self.separator.output_dir = str(temp_output_dir)
            output_files = self.separator.separate(str(actual_input_path))
            
            # å°‹æ‰¾ Vocals æª”æ¡ˆ
            vocals_file = next((f for f in output_files if f is not None and str(f) and ('vocals' in str(f).lower() or '(vocals)' in str(f).lower())), None)
            
            if vocals_file:
                # æª¢æŸ¥å¤šå€‹å¯èƒ½çš„ä½ç½®
                possible_locations = [
                    temp_output_dir / str(vocals_file),                    # æŒ‡å®šçš„æš«å­˜ç›®éŒ„
                    self.temp_dir / str(vocals_file),                     # ä¸»æš«å­˜ç›®éŒ„
                    Path.cwd() / str(vocals_file),                        # å·¥ä½œç›®éŒ„
                    Path(str(vocals_file))                                # çµ•å°è·¯å¾‘
                ]
                
                vocals_path = None
                for location in possible_locations:
                    if location.exists():
                        vocals_path = location
                        break
                
                if vocals_path is None:
                    # å¦‚æœé‚„æ˜¯æ‰¾ä¸åˆ°ï¼Œå˜—è©¦æœå°‹æ•´å€‹æš«å­˜ç›®éŒ„
                    vocals_filename = Path(vocals_file).name
                    
                    # æœå°‹æ‰€æœ‰å¯èƒ½çš„ä½ç½®
                    for search_dir in [temp_output_dir, self.temp_dir, Path.cwd()]:
                        for found_file in search_dir.rglob(vocals_filename):
                            if found_file.exists():
                                vocals_path = found_file
                                break
                        if vocals_path:
                            break
                
                if vocals_path is None:
                    self.logger.error(f"âŒ å®Œå…¨æ‰¾ä¸åˆ° Vocals æª”æ¡ˆ: {vocals_file}")
                
                if vocals_path:
                    # å¦‚æœé€²è¡Œäº†é è™•ç†ï¼ˆè£œé›¶ï¼‰ï¼Œéœ€è¦é‚„åŸåˆ°åŸå§‹é•·åº¦
                    if preprocessed_file and original_duration > 0:
                        self.logger.debug(f"ğŸ”§ é‚„åŸéŸ³é »é•·åº¦: 15.00s â†’ {original_duration:.2f}s")
                        
                        # è¼‰å…¥è™•ç†å¾Œçš„äººè²æª”æ¡ˆ
                        processed_waveform, processed_sample_rate = torchaudio.load(str(vocals_path))
                        
                        # è¨ˆç®—åŸå§‹éŸ³é »çš„æ¨£æœ¬æ•¸
                        original_samples = int(original_duration * processed_sample_rate)
                        
                        # å¾è£œé›¶éŸ³é »ä¸­æå–åŸå§‹é•·åº¦éƒ¨åˆ†ï¼ˆç§»é™¤å‰å¾Œè£œé›¶ï¼‰
                        # è£œé›¶æ˜¯å‰å¾Œå¹³å‡åˆ†é…çš„ï¼Œæ‰€ä»¥å¾ä¸­é–“æå–åŸå§‹é•·åº¦
                        total_samples = processed_waveform.shape[1]
                        padding_samples = total_samples - original_samples
                        padding_before = padding_samples // 2
                        
                        # æå–åŸå§‹éŸ³é »éƒ¨åˆ†
                        restored_waveform = processed_waveform[:, padding_before:padding_before + original_samples]
                        
                        # ä¿å­˜é‚„åŸé•·åº¦çš„éŸ³é »
                        temp_restored_file = temp_output_dir / f"restored_{Path(vocals_file).name}"
                        torchaudio.save(str(temp_restored_file), restored_waveform, processed_sample_rate)
                        
                        # ç¢ºä¿é‚„åŸæª”æ¡ˆå­˜åœ¨å†ç§»å‹•
                        if temp_restored_file.exists():
                            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
                            output_path.parent.mkdir(parents=True, exist_ok=True)
                            shutil.move(str(temp_restored_file), str(output_path))
                        else:
                            raise FileNotFoundError(f"é‚„åŸæª”æ¡ˆç”Ÿæˆå¤±æ•—: {temp_restored_file}")
                        self.logger.info(f"âœ… äººè²åˆ†é›¢å®Œæˆ: {input_path.name} (é‚„åŸ: {original_duration:.2f}s)")
                    else:
                        # æ²’æœ‰é è™•ç†çš„æƒ…æ³ï¼Œç›´æ¥ç§»å‹•
                        if vocals_path.exists():
                            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
                            output_path.parent.mkdir(parents=True, exist_ok=True)
                            shutil.move(str(vocals_path), str(output_path))
                        else:
                            raise FileNotFoundError(f"Vocals æª”æ¡ˆä¸å­˜åœ¨: {vocals_path}")
                        self.logger.info(f"âœ… äººè²åˆ†é›¢å®Œæˆ: {input_path.name} (åŸå§‹: {original_duration:.2f}s)")
                    
                    result['enhanced'] = True
            else:
                raise RuntimeError("äººè²æª”æ¡ˆç”Ÿæˆå¤±æ•—")

            result['success'] = True
            
            # è™•ç†æˆåŠŸå¾Œï¼Œå‰µå»ºå®Œæˆæ¨™è¨˜
            if backup_original and output_path == input_path and 'backup_file' in result:
                backup_path = Path(result['backup_file'])
                completed_backup_path = input_path.with_suffix('.bak.completed')
                
                # å°‡ .bak é‡å‘½åç‚º .bak.completed è¡¨ç¤ºè™•ç†å®Œæˆ
                if backup_path.exists():
                    backup_path.rename(completed_backup_path)
                    result['backup_file'] = str(completed_backup_path)
                    self.logger.debug(f"âœ… æ¨™è¨˜è™•ç†å®Œæˆ: {completed_backup_path.name}")

        except Exception as e:
            # --- éŒ¯èª¤è™•ç† ---
            result['error'] = str(e)
            self.logger.error(f"âŒ äººè²åˆ†é›¢å¤±æ•— {input_path.name}: {e}")
            self.logger.debug(f"Exception traceback: {traceback.format_exc()}")
            
            if backup_original and 'backup_file' in result:
                backup_path = Path(result['backup_file'])
                if backup_path.exists():
                    backup_path.rename(output_path)
        
        finally:
            # --- è³‡æºæ¸…ç† ---
            if temp_output_dir and temp_output_dir.exists():
                shutil.rmtree(temp_output_dir, ignore_errors=True)
            
            if preprocessed_file and Path(preprocessed_file).exists():
                try:
                    Path(preprocessed_file).unlink()
                except OSError as e:
                    self.logger.warning(f"âš ï¸  æ¸…ç†é è™•ç†æª”æ¡ˆå¤±æ•—: {e}")
            
            # é¡å¤–æ¸…ç†ï¼šæ¸…é™¤å¯èƒ½æ•£è½åœ¨å·¥ä½œç›®éŒ„çš„ä¼´å¥æª”æ¡ˆ
            try:
                current_dir = Path.cwd()
                for pattern in ['*_(Instrumental)_*.wav', 'padded_*_(Instrumental)_*.wav']:
                    for leftover_file in current_dir.glob(pattern):
                        leftover_file.unlink()
                        self.logger.debug(f"ğŸ§¹ æ¸…ç†æ•£è½æª”æ¡ˆ: {leftover_file.name}")
            except Exception as e:
                self.logger.debug(f"æ¸…ç†æ•£è½æª”æ¡ˆæ™‚å‡ºç¾éŒ¯èª¤: {e}")
            
            # æ¸…ç†æ­¤æª”æ¡ˆç›¸é—œçš„ temp æª”æ¡ˆ
            try:
                input_filename = input_path.stem
                for temp_file in self.temp_dir.glob(f"*{input_filename}*"):
                    temp_file.unlink()
                    self.logger.debug(f"ğŸ§¹ æ¸…ç†æš«å­˜æª”æ¡ˆ: {temp_file.name}")
            except Exception as e:
                self.logger.debug(f"æ¸…ç†æš«å­˜æª”æ¡ˆæ™‚å‡ºç¾éŒ¯èª¤: {e}")
            
            if self.device == 'cuda':
                torch.cuda.empty_cache()
            gc.collect()

        # æ›´æ–°æœ€çµ‚çµ±è¨ˆæ•¸æ“š
        result['processing_time'] = time.time() - start_time
        current_memory = psutil.Process().memory_info().rss / (1024**2)
        result['memory_usage_mb'] = current_memory - initial_memory
        
        return result
    
    def _analyze_directory_structure(self, input_dir: Path, audio_files: List[Path]):
        """åˆ†æä¸¦é¡¯ç¤ºç›®éŒ„çµæ§‹çµ±è¨ˆ"""
        print("\n" + "="*60)
        print("ğŸ“Š ç›®éŒ„çµæ§‹åˆ†æ")
        print("="*60)
        
        # çµ±è¨ˆæ¯å€‹å­ç›®éŒ„çš„æª”æ¡ˆæ•¸é‡
        dir_stats = {}
        for audio_file in audio_files:
            # å–å¾—ç›¸å°æ–¼è¼¸å…¥ç›®éŒ„çš„è·¯å¾‘
            relative_path = audio_file.relative_to(input_dir)
            parent_dir = str(relative_path.parent) if relative_path.parent != Path('.') else 'æ ¹ç›®éŒ„'
            
            if parent_dir not in dir_stats:
                dir_stats[parent_dir] = 0
            dir_stats[parent_dir] += 1
        
        print(f"ğŸ“ åŸºç¤ç›®éŒ„: {input_dir}")
        print(f"ğŸµ ç¸½éŸ³æª”æ•¸: {len(audio_files)}")
        print(f"ğŸ“‚ å­ç›®éŒ„æ•¸: {len(dir_stats)}")
        print("\nğŸ“‹ å„ç›®éŒ„æª”æ¡ˆåˆ†å¸ƒ:")
        
        # æŒ‰æª”æ¡ˆæ•¸é‡æ’åºé¡¯ç¤º
        sorted_dirs = sorted(dir_stats.items(), key=lambda x: x[1], reverse=True)
        for dir_name, file_count in sorted_dirs:
            print(f"  ğŸ“ {dir_name}: {file_count} æª”æ¡ˆ")
        
        print("="*60)
    
    def batch_enhance(self, input_dir: str, pattern: str = "*.wav",
                     backup_original: bool = False) -> Dict:
        """
        æ‰¹é‡è™•ç†ç›®éŒ„ä¸‹çš„éŸ³æª”
        
        Args:
            input_dir: è¼¸å…¥ç›®éŒ„
            pattern: æª”æ¡ˆåŒ¹é…æ¨¡å¼
            backup_original: æ˜¯å¦å‚™ä»½åŸå§‹æª”æ¡ˆ
            
        Returns:
            Dict: æ‰¹é‡è™•ç†çµæœ
        """
        input_dir = Path(input_dir)
        if not input_dir.exists():
            raise FileNotFoundError(f"è¼¸å…¥ç›®éŒ„ä¸å­˜åœ¨: {input_dir}")
        
        # å°‹æ‰¾éŸ³æª” - æ”¯æ´å·¢ç‹€ç›®éŒ„æœå°‹ (rglob æœƒéè¿´æœå°‹æ‰€æœ‰å­ç›®éŒ„)
        audio_files = list(input_dir.rglob(pattern))
        if not audio_files:
            self.logger.warning(f"åœ¨ {input_dir} ä¸­æœªæ‰¾åˆ°åŒ¹é… {pattern} çš„éŸ³æª”")
            return {'success': False, 'error': 'No audio files found'}
        
        # åˆ†æç›®éŒ„çµæ§‹
        self._analyze_directory_structure(input_dir, audio_files)
        
        self.logger.info(f"ğŸ“ æ‰¾åˆ° {len(audio_files)} å€‹éŸ³æª”é€²è¡Œè™•ç†")
        
        # é‡ç½®çµ±è¨ˆ
        self.stats = {
            'processed_files': 0,
            'failed_files': 0,
            'total_time': 0,
            'failed_list': [],
            'preprocessed_files': 0,
            'short_audio_count': 0,
            'average_original_duration': 0
        }
        
        start_time = time.time()
        
        # æ‰¹é‡è™•ç†
        for audio_file in tqdm(audio_files, desc="ğŸµ UVR5 äººè²åˆ†é›¢"):
            try:
                result = self.enhance_audio(str(audio_file), backup_original=backup_original)
                
                if result['success']:
                    self.stats['processed_files'] += 1
                    # çµ±è¨ˆé è™•ç†è³‡è¨Š
                    if result.get('preprocessed', False):
                        self.stats['preprocessed_files'] += 1
                    if result.get('original_duration', 0) > 0 and result.get('original_duration', 0) < self.min_duration:
                        self.stats['short_audio_count'] += 1
                    
                    # è¨˜éŒ„æˆåŠŸè™•ç†çš„è©³ç´°ä¿¡æ¯
                    processing_time = result.get('processing_time', 0)
                    memory_usage = result.get('memory_usage_mb', 0)
                    self.logger.debug(f"âœ… æˆåŠŸè™•ç† {audio_file.name}: {processing_time:.2f}s, {memory_usage:.1f}MB")
                else:
                    self.stats['failed_files'] += 1
                    error_msg = result.get('error', 'Unknown error')
                    self.stats['failed_list'].append({
                        'file': str(audio_file),
                        'error': error_msg,
                        'processing_time': result.get('processing_time', 0)
                    })
                    self.logger.error(f"âŒ è™•ç†å¤±æ•— {audio_file.name}: {error_msg}")
                
            except Exception as e:
                self.stats['failed_files'] += 1
                error_msg = f"Unexpected error: {str(e)}"
                self.stats['failed_list'].append({
                    'file': str(audio_file),
                    'error': error_msg,
                    'exception_type': type(e).__name__
                })
                self.logger.error(f"âŒ è™•ç†å¤±æ•— {audio_file.name}: {error_msg}")
                # è¨˜éŒ„å®Œæ•´çš„éŒ¯èª¤å †ç–Šè¿½è¹¤
                self.logger.debug(f"Exception traceback: {traceback.format_exc()}")
        
        self.stats['total_time'] = time.time() - start_time
        
        # ç”Ÿæˆå ±å‘Š
        self._generate_batch_report()
        
        return {
            'success': True,
            'stats': self.stats,
            'total_files': len(audio_files),
            'processed_files': self.stats['processed_files'],
            'failed_files': self.stats['failed_files']
        }
    
    def enhance_split_dataset(self, split_dir: str, backup_original: bool = False) -> Dict:
        """
        å°åˆ‡åˆ†å¾Œçš„è¨“ç·´/æ¸¬è©¦é›†é€²è¡Œå¢å¼·è™•ç†
        
        Args:
            split_dir: split_dataset ç›®éŒ„è·¯å¾‘
            backup_original: æ˜¯å¦å‚™ä»½åŸå§‹æª”æ¡ˆ
            
        Returns:
            Dict: è™•ç†çµæœ
        """
        split_dir = Path(split_dir)
        if not split_dir.exists():
            raise FileNotFoundError(f"åˆ‡åˆ†è³‡æ–™é›†ç›®éŒ„ä¸å­˜åœ¨: {split_dir}")
        
        results = {}
        
        # è™•ç† train å’Œ test ç›®éŒ„
        for subset in ['train', 'test']:
            subset_dir = split_dir / subset
            if not subset_dir.exists():
                self.logger.warning(f"âš ï¸  {subset} ç›®éŒ„ä¸å­˜åœ¨: {subset_dir}")
                continue
            
            self.logger.info(f"ğŸ“Š é–‹å§‹è™•ç† {subset} è³‡æ–™é›†...")
            
            # è™•ç†æ¯å€‹èªªè©±äººç›®éŒ„
            speaker_dirs = [d for d in subset_dir.iterdir() if d.is_dir()]
            subset_results = []
            
            for speaker_dir in speaker_dirs:
                self.logger.info(f"ğŸ‘¤ è™•ç†èªªè©±äºº: {speaker_dir.name}")
                
                try:
                    result = self.batch_enhance(
                        str(speaker_dir), 
                        pattern="*.wav",
                        backup_original=backup_original
                    )
                    result['speaker'] = speaker_dir.name
                    subset_results.append(result)
                    
                except Exception as e:
                    self.logger.error(f"âŒ èªªè©±äºº {speaker_dir.name} è™•ç†å¤±æ•—: {e}")
                    # è¨˜éŒ„å®Œæ•´çš„éŒ¯èª¤å †ç–Šè¿½è¹¤
                    self.logger.debug(f"Exception traceback: {traceback.format_exc()}")
                    subset_results.append({
                        'speaker': speaker_dir.name,
                        'success': False,
                        'error': str(e)
                    })
            
            results[subset] = subset_results
        
        # ç”Ÿæˆæ•´é«”å ±å‘Š
        self._generate_split_dataset_report(results)
        
        return {
            'success': True,
            'results': results
        }
    
    def _generate_batch_report(self):
        """ç”Ÿæˆæ‰¹é‡è™•ç†å ±å‘Š - æŒ‰ç›®éŒ„çµæ§‹åˆ†çµ„é¡¯ç¤º"""
        print("\n" + "="*80)
        print("ğŸµ UVR5 éŸ³é »å¢å¼·æ‰¹é‡è™•ç†å ±å‘Š")
        print("="*80)
        print(f"ğŸ“Š è™•ç†çµ±è¨ˆ:")
        print(f"  æˆåŠŸè™•ç†: {self.stats['processed_files']} æª”æ¡ˆ")
        print(f"  è™•ç†å¤±æ•—: {self.stats['failed_files']} æª”æ¡ˆ")
        print(f"  ç¸½è™•ç†æ™‚é–“: {self.stats['total_time']:.2f} ç§’")
        
        if self.stats['processed_files'] > 0:
            avg_time = self.stats['total_time'] / self.stats['processed_files']
            print(f"  å¹³å‡è™•ç†æ™‚é–“: {avg_time:.2f} ç§’/æª”")
        
        if self.stats['failed_files'] > 0:
            print(f"\nâŒ å¤±æ•—æª”æ¡ˆæ¸…å–® (æŒ‰ç›®éŒ„åˆ†çµ„):")
            # æŒ‰ç›®éŒ„åˆ†çµ„å¤±æ•—æª”æ¡ˆ
            failed_by_dir = {}
            for failed in self.stats['failed_list']:
                file_path = Path(failed['file'])
                dir_name = str(file_path.parent)
                if dir_name not in failed_by_dir:
                    failed_by_dir[dir_name] = []
                failed_by_dir[dir_name].append({
                    'filename': file_path.name,
                    'error': failed['error']
                })
            
            # é¡¯ç¤ºæ¯å€‹ç›®éŒ„çš„å¤±æ•—æª”æ¡ˆ
            for dir_name, files in failed_by_dir.items():
                print(f"\nğŸ“ ç›®éŒ„: {dir_name}")
                for file_info in files:
                    print(f"    â€¢ {file_info['filename']}: {file_info['error']}")
                print(f"    å°è¨ˆ: {len(files)} å€‹å¤±æ•—æª”æ¡ˆ")
    
    def _generate_split_dataset_report(self, results: Dict):
        """ç”Ÿæˆåˆ‡åˆ†è³‡æ–™é›†è™•ç†å ±å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“Š åˆ‡åˆ†è³‡æ–™é›† UVR5 å¢å¼·å ±å‘Š")
        print("="*60)
        
        for subset, subset_results in results.items():
            print(f"\nğŸ“ {subset.upper()} è³‡æ–™é›†:")
            
            total_speakers = len(subset_results)
            successful_speakers = sum(1 for r in subset_results if r.get('success', False))
            total_files = sum(r.get('processed_files', 0) for r in subset_results if r.get('success', False))
            
            print(f"  èªªè©±äººç¸½æ•¸: {total_speakers}")
            print(f"  æˆåŠŸè™•ç†èªªè©±äºº: {successful_speakers}")
            print(f"  ç¸½è™•ç†æª”æ¡ˆæ•¸: {total_files}")
            
            # é¡¯ç¤ºå¤±æ•—çš„èªªè©±äºº
            failed_speakers = [r for r in subset_results if not r.get('success', False)]
            if failed_speakers:
                print(f"  âŒ å¤±æ•—èªªè©±äºº:")
                for failed in failed_speakers:
                    print(f"    â€¢ {failed['speaker']}: {failed.get('error', 'Unknown error')}")
    
    def get_model_info(self) -> Dict:
        """ç²å–æ¨¡å‹è³‡è¨Š"""
        model_file = self.model_path / self.vocal_model
        
        return {
            'model_path': str(self.model_path),
            'vocal_model': self.vocal_model,
            'model_exists': model_file.exists(),
            'model_size_mb': model_file.stat().st_size / (1024**2) if model_file.exists() else 0,
            'device': self.device,
            'batch_size': self.batch_size,
            'min_duration': self.min_duration,
            'target_duration': self.target_duration,
            'processing_timeout': self.processing_timeout
        }
    
    def cleanup(self):
        """æ¸…ç†è³‡æº"""
        if self.separator:
            del self.separator
            self.separator = None
        
        if self.device == 'cuda':
            torch.cuda.empty_cache()
        
        gc.collect()
        self.logger.info("ğŸ§¹ UVR5 è™•ç†å™¨è³‡æºæ¸…ç†å®Œæˆ")
        # è¨˜éŒ„æœ€çµ‚çš„ GPU è¨˜æ†¶é«”ç‹€æ…‹
        if self.device == 'cuda' and torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated(0) / (1024**3)
            reserved = torch.cuda.memory_reserved(0) / (1024**3)
            self.logger.debug(f"ğŸ“Š GPU è¨˜æ†¶é«”æ¸…ç†å¾Œ: å·²åˆ†é… {allocated:.2f}GB, å·²ä¿ç•™ {reserved:.2f}GB")


class ThreadedUVR5Processor(UVR5Processor):
    """å¤šåŸ·è¡Œç·’ UVR5 è™•ç†å™¨ - æ”¯æ´ä¸¦è¡Œè™•ç†ä»¥æå‡å¤§æ‰¹é‡æª”æ¡ˆçš„è™•ç†é€Ÿåº¦"""
    
    def __init__(self, max_workers: int = 1, **kwargs):
        """
        åˆå§‹åŒ–å¤šåŸ·è¡Œç·’ UVR5 è™•ç†å™¨
        
        Args:
            max_workers: æœ€å¤§ä¸¦è¡ŒåŸ·è¡Œç·’æ•¸ï¼Œ1=å–®åŸ·è¡Œç·’ï¼Œ2+=å¤šåŸ·è¡Œç·’
            **kwargs: å‚³éçµ¦çˆ¶é¡åˆ¥çš„å…¶ä»–åƒæ•¸
        """
        super().__init__(**kwargs)
        self.max_workers = max(1, int(max_workers))  # ç¢ºä¿è‡³å°‘ç‚º 1
        self.logger.info(f"ğŸš€ å¤šåŸ·è¡Œç·’ UVR5 è™•ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œä¸¦è¡Œæ•¸: {self.max_workers}")
    
    def batch_enhance(self, input_dir: str, pattern: str = "*.wav",
                     backup_original: bool = False) -> Dict:
        """
        å¤šåŸ·è¡Œç·’æ‰¹é‡è™•ç†ç›®éŒ„ä¸‹çš„éŸ³æª”
        
        Args:
            input_dir: è¼¸å…¥ç›®éŒ„
            pattern: æª”æ¡ˆåŒ¹é…æ¨¡å¼
            backup_original: æ˜¯å¦å‚™ä»½åŸå§‹æª”æ¡ˆ
            
        Returns:
            Dict: æ‰¹é‡è™•ç†çµæœ
        """
        input_dir = Path(input_dir)
        if not input_dir.exists():
            raise FileNotFoundError(f"è¼¸å…¥ç›®éŒ„ä¸å­˜åœ¨: {input_dir}")
        
        # å°‹æ‰¾éŸ³æª” - æ”¯æ´å·¢ç‹€ç›®éŒ„æœå°‹ (rglob æœƒéè¿´æœå°‹æ‰€æœ‰å­ç›®éŒ„)
        audio_files = list(input_dir.rglob(pattern))
        if not audio_files:
            self.logger.warning(f"åœ¨ {input_dir} ä¸­æœªæ‰¾åˆ°åŒ¹é… {pattern} çš„éŸ³æª”")
            return {'success': False, 'error': 'No audio files found'}
        
        total_files = len(audio_files)
        
        # åˆ†æç›®éŒ„çµæ§‹
        self._analyze_directory_structure(input_dir, audio_files)
        
        self.logger.info(f"ğŸ“ æ‰¾åˆ° {total_files} å€‹éŸ³æª”é€²è¡Œè™•ç†")
        
        # æ ¹æ“šä¸¦è¡Œæ•¸é¸æ“‡è™•ç†æ–¹å¼
        if self.max_workers <= 1:
            self.logger.info("ğŸ”„ ä½¿ç”¨å–®åŸ·è¡Œç·’æ¨¡å¼è™•ç†")
            return self._single_thread_batch_enhance(audio_files, backup_original)
        else:
            self.logger.info(f"ğŸš€ ä½¿ç”¨å¤šåŸ·è¡Œç·’æ¨¡å¼è™•ç†ï¼Œä¸¦è¡Œæ•¸: {self.max_workers}")
            return self._multi_thread_batch_enhance(audio_files, backup_original)
    
    def _single_thread_batch_enhance(self, audio_files: List[Path], backup_original: bool) -> Dict:
        """å–®åŸ·è¡Œç·’æ‰¹é‡è™•ç†ï¼ˆåŸæœ‰é‚è¼¯ï¼‰"""
        # é‡ç½®çµ±è¨ˆ
        self.stats = {
            'processed_files': 0,
            'failed_files': 0,
            'total_time': 0,
            'failed_list': [],
            'preprocessed_files': 0,
            'short_audio_count': 0
        }
        
        start_time = time.time()
        
        # æ‰¹é‡è™•ç†
        for audio_file in tqdm(audio_files, desc="ğŸµ UVR5 äººè²åˆ†é›¢"):
            try:
                result = self.enhance_audio(str(audio_file), backup_original=backup_original)
                
                if result['success']:
                    self.stats['processed_files'] += 1
                else:
                    self.stats['failed_files'] += 1
                    self.stats['failed_list'].append({
                        'file': str(audio_file),
                        'error': result.get('error', 'Unknown error')
                    })
                
            except Exception as e:
                self.stats['failed_files'] += 1
                self.stats['failed_list'].append({
                    'file': str(audio_file),
                    'error': str(e)
                })
                self.logger.error(f"âŒ è™•ç†å¤±æ•— {audio_file.name}: {e}")
        
        self.stats['total_time'] = time.time() - start_time
        
        # ç”Ÿæˆå ±å‘Š
        self._generate_batch_report()
        
        return {
            'success': True,
            'stats': self.stats,
            'total_files': len(audio_files),
            'processed_files': self.stats['processed_files'],
            'failed_files': self.stats['failed_files']
        }
    
    def _multi_thread_batch_enhance(self, audio_files: List[Path], backup_original: bool) -> Dict:
        """å¤šåŸ·è¡Œç·’æ‰¹é‡è™•ç†"""
        start_time = time.time()
        
        # æª¢æŸ¥ GPU è¨˜æ†¶é«”ä¸¦å‹•æ…‹èª¿æ•´åŸ·è¡Œç·’æ•¸
        actual_workers = self._check_gpu_memory()
        if actual_workers <= 1:
            self.logger.warning("âš ï¸  GPU è¨˜æ†¶é«”ä¸è¶³ï¼Œé™ç´šåˆ°å–®åŸ·è¡Œç·’æ¨¡å¼")
            return self._single_thread_batch_enhance(audio_files, backup_original)
        elif actual_workers < self.max_workers:
            # å‹•æ…‹èª¿æ•´åŸ·è¡Œç·’æ•¸
            original_workers = self.max_workers
            self.max_workers = actual_workers
            self.logger.info(f"ğŸ”§ å‹•æ…‹èª¿æ•´åŸ·è¡Œç·’æ•¸: {original_workers} â†’ {actual_workers}")
        
        # åˆå§‹åŒ–çµ±è¨ˆ
        stats = {
            'processed_files': 0,
            'failed_files': 0,
            'total_time': 0,
            'failed_list': []
        }
        
        # å‰µå»ºåŸ·è¡Œç·’æ± å’Œ UVR5 è™•ç†å™¨å¯¦ä¾‹
        processors = []
        try:
            self.logger.info(f"ğŸ”§ å‰µå»º {self.max_workers} å€‹ UVR5 è™•ç†å™¨å¯¦ä¾‹...")
            for i in range(self.max_workers):
                processor = UVR5Processor(
                    model_path=str(self.model_path),
                    vocal_model=self.vocal_model,
                    device=self.device,
                    batch_size=self.batch_size,
                    min_duration=self.min_duration,
                    target_duration=self.target_duration
                )
                processors.append(processor)
            
            # å¤šåŸ·è¡Œç·’è™•ç†
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                # æäº¤ä»»å‹™
                future_to_file = {}
                for i, audio_file in enumerate(audio_files):
                    processor = processors[i % self.max_workers]
                    future = executor.submit(
                        processor.enhance_audio, 
                        str(audio_file), 
                        backup_original=backup_original
                    )
                    future_to_file[future] = audio_file
                
                # æ”¶é›†çµæœä¸¦é¡¯ç¤ºé€²åº¦
                progress_bar = tqdm(total=len(audio_files), desc="ğŸš€ å¤šåŸ·è¡Œç·’ UVR5 äººè²åˆ†é›¢")
                for future in as_completed(future_to_file):
                    audio_file = future_to_file[future]
                    try:
                        result = future.result()
                        if result['success']:
                            stats['processed_files'] += 1
                        else:
                            stats['failed_files'] += 1
                            stats['failed_list'].append({
                                'file': str(audio_file),
                                'error': result.get('error', 'Unknown error')
                            })
                    except Exception as e:
                        stats['failed_files'] += 1
                        stats['failed_list'].append({
                            'file': str(audio_file),
                            'error': str(e)
                        })
                        self.logger.error(f"âŒ å¤šåŸ·è¡Œç·’è™•ç†å¤±æ•— {audio_file.name}: {e}")
                    
                    progress_bar.update(1)
                
                progress_bar.close()
            
        finally:
            # æ¸…ç†æ‰€æœ‰è™•ç†å™¨å¯¦ä¾‹
            for processor in processors:
                try:
                    processor.cleanup()
                except Exception as e:
                    self.logger.warning(f"âš ï¸  æ¸…ç†è™•ç†å™¨æ™‚å‡ºéŒ¯: {e}")
                    self.logger.debug(f"Cleanup exception traceback: {traceback.format_exc()}")
        
        stats['total_time'] = time.time() - start_time
        
        # ç”Ÿæˆå ±å‘Š
        self._generate_threaded_batch_report(stats, len(audio_files))
        
        return {
            'success': True,
            'stats': stats,
            'total_files': len(audio_files),
            'processed_files': stats['processed_files'],
            'failed_files': stats['failed_files']
        }
    
    def _check_gpu_memory(self) -> int:
        """æª¢æŸ¥ GPU è¨˜æ†¶é«”ä¸¦è¿”å›å»ºè­°çš„åŸ·è¡Œç·’æ•¸"""
        if self.device != 'cuda' or not torch.cuda.is_available():
            return self.max_workers  # CPU æ¨¡å¼ä½¿ç”¨åŸå§‹è¨­å®š
        
        try:
            # ç²å– GPU è¨˜æ†¶é«”è³‡è¨Š
            gpu_memory = torch.cuda.get_device_properties(0).total_memory
            gpu_free = gpu_memory - torch.cuda.memory_reserved(0)
            
            # å‹•æ…‹èª¿æ•´æ¯å€‹ worker çš„è¨˜æ†¶é«”ä½¿ç”¨é‡
            # åŸºæ–¼ GPU ç¸½è¨˜æ†¶é«”å®¹é‡æ™ºæ…§åˆ†é…
            gpu_memory_gb = gpu_memory / (1024**3)
            
            if gpu_memory_gb >= 70:      # H100, A100 80GB ç­‰é«˜ç«¯å¡
                estimated_memory_per_worker = 2.8 * 1024**3  # 2.8GB (å¯è·‘ ~28 ä¸¦è¡Œ)
                self.logger.info(f"ğŸš€ æª¢æ¸¬åˆ°é«˜ç«¯ GPU ({gpu_memory_gb:.0f}GB)ï¼Œä½¿ç”¨ç©æ¥µä¸¦è¡Œç­–ç•¥")
            elif gpu_memory_gb >= 40:    # A6000, RTX 6000 Ada ç­‰
                estimated_memory_per_worker = 3.2 * 1024**3  # 3.2GB (å¯è·‘ ~12 ä¸¦è¡Œ)
                self.logger.info(f"ğŸ¯ æª¢æ¸¬åˆ°å°ˆæ¥­ç´š GPU ({gpu_memory_gb:.0f}GB)ï¼Œä½¿ç”¨å¹³è¡¡ç­–ç•¥")
            elif gpu_memory_gb >= 20:    # RTX 4090, 3090 ç­‰
                estimated_memory_per_worker = 3.5 * 1024**3  # 3.5GB (å¯è·‘ ~6 ä¸¦è¡Œ)
                self.logger.info(f"ğŸ® æª¢æ¸¬åˆ°é«˜ç«¯éŠæˆ²å¡ ({gpu_memory_gb:.0f}GB)ï¼Œä½¿ç”¨å„ªåŒ–ç­–ç•¥")
            elif gpu_memory_gb >= 11:    # RTX 3060 12GB, 4060 Ti ç­‰
                estimated_memory_per_worker = 3.0 * 1024**3  # 3.0GB (å¯è·‘ ~4 ä¸¦è¡Œ)
                self.logger.info(f"âš¡ æª¢æ¸¬åˆ°ä¸­ç«¯å¡ ({gpu_memory_gb:.0f}GB)ï¼Œä½¿ç”¨é©ä¸­ç­–ç•¥")
            else:                        # 8GB ä»¥ä¸‹å¡
                estimated_memory_per_worker = 2.5 * 1024**3  # 2.5GB (å¯è·‘ ~3 ä¸¦è¡Œ)
                self.logger.info(f"ğŸ’¡ æª¢æ¸¬åˆ°å…¥é–€å¡ ({gpu_memory_gb:.0f}GB)ï¼Œä½¿ç”¨ä¿å®ˆç­–ç•¥")
            
            # è¨ˆç®—ç†è«–ä¸Šå¯æ”¯æ´çš„æœ€å¤§åŸ·è¡Œç·’æ•¸
            max_possible_workers = max(1, int(gpu_free // estimated_memory_per_worker))
            
            # é¸æ“‡è¼ƒå°çš„å€¼ï¼šç”¨æˆ¶è¨­å®š vs è¨˜æ†¶é«”é™åˆ¶
            recommended_workers = min(self.max_workers, max_possible_workers)
            
            self.logger.info(f"ğŸ“Š GPU è¨˜æ†¶é«”æª¢æŸ¥:")
            self.logger.info(f"  ç¸½è¨˜æ†¶é«”: {gpu_memory / 1024**3:.1f} GB")
            self.logger.info(f"  å¯ç”¨è¨˜æ†¶é«”: {gpu_free / 1024**3:.1f} GB")
            self.logger.info(f"  ç”¨æˆ¶è¨­å®šåŸ·è¡Œç·’: {self.max_workers}")
            self.logger.info(f"  è¨˜æ†¶é«”å¯æ”¯æ´åŸ·è¡Œç·’: {max_possible_workers}")
            self.logger.info(f"  å¯¦éš›ä½¿ç”¨åŸ·è¡Œç·’: {recommended_workers}")
            
            if recommended_workers < self.max_workers:
                self.logger.warning(f"âš ï¸  GPU è¨˜æ†¶é«”ä¸è¶³ä»¥æ”¯æ´ {self.max_workers} åŸ·è¡Œç·’ï¼Œè‡ªå‹•èª¿æ•´ç‚º {recommended_workers} åŸ·è¡Œç·’")
            
            return recommended_workers
            
        except Exception as e:
            self.logger.warning(f"âš ï¸  ç„¡æ³•æª¢æŸ¥ GPU è¨˜æ†¶é«”: {e}")
            return self.max_workers  # æª¢æŸ¥å¤±æ•—æ™‚ä½¿ç”¨åŸå§‹è¨­å®š
            
        except Exception as e:
            self.logger.error(f"âŒ GPU è¨˜æ†¶é«”æª¢æŸ¥å‡ºç¾æ„å¤–éŒ¯èª¤: {e}")
            self.logger.debug(f"GPU memory check exception: {traceback.format_exc()}")
            return True  # å‡ºç¾æ„å¤–éŒ¯èª¤æ™‚å…è¨±ç¹¼çºŒ
    
    def _generate_threaded_batch_report(self, stats: Dict, total_files: int):
        """ç”Ÿæˆå¤šåŸ·è¡Œç·’æ‰¹é‡è™•ç†å ±å‘Š - æŒ‰ç›®éŒ„çµæ§‹åˆ†çµ„é¡¯ç¤º"""
        print("\n" + "="*80)
        print("ğŸš€ å¤šåŸ·è¡Œç·’ UVR5 äººè²åˆ†é›¢æ‰¹é‡è™•ç†å ±å‘Š")
        print("="*80)
        print(f"ğŸ“Š è™•ç†çµ±è¨ˆ:")
        print(f"  ä¸¦è¡ŒåŸ·è¡Œç·’æ•¸: {self.max_workers}")
        print(f"  æˆåŠŸè™•ç†: {stats['processed_files']} æª”æ¡ˆ")
        print(f"  è™•ç†å¤±æ•—: {stats['failed_files']} æª”æ¡ˆ")
        print(f"  ç¸½è™•ç†æ™‚é–“: {stats['total_time']:.2f} ç§’")
        
        if stats['processed_files'] > 0:
            avg_time = stats['total_time'] / stats['processed_files']
            print(f"  å¹³å‡è™•ç†æ™‚é–“: {avg_time:.2f} ç§’/æª”")
            
            # ä¼°ç®—åŠ é€Ÿæ¯”ï¼ˆç›¸å°æ–¼å–®åŸ·è¡Œç·’ï¼‰
            estimated_single_thread_time = stats['total_time'] * self.max_workers
            speedup = estimated_single_thread_time / stats['total_time']
            print(f"  ä¼°ç®—åŠ é€Ÿæ¯”: {speedup:.1f}x")
        
        if stats['failed_files'] > 0:
            print(f"\nâŒ å¤±æ•—æª”æ¡ˆæ¸…å–® (æŒ‰ç›®éŒ„åˆ†çµ„):")
            # æŒ‰ç›®éŒ„åˆ†çµ„å¤±æ•—æª”æ¡ˆ
            failed_by_dir = {}
            for failed in stats['failed_list']:
                file_path = Path(failed['file'])
                dir_name = str(file_path.parent)
                if dir_name not in failed_by_dir:
                    failed_by_dir[dir_name] = []
                failed_by_dir[dir_name].append({
                    'filename': file_path.name,
                    'error': failed['error']
                })
            
            # é¡¯ç¤ºæ¯å€‹ç›®éŒ„çš„å¤±æ•—æª”æ¡ˆ
            for dir_name, files in failed_by_dir.items():
                print(f"\nğŸ“ ç›®éŒ„: {dir_name}")
                for file_info in files:
                    print(f"    â€¢ {file_info['filename']}: {file_info['error']}")
                print(f"    å°è¨ˆ: {len(files)} å€‹å¤±æ•—æª”æ¡ˆ")


def main():
    """æ¸¬è©¦ UVR5 è™•ç†å™¨"""
    print("ğŸ¯ UVR5 è™•ç†å™¨æ¸¬è©¦")
    print("=" * 50)
    
    try:
        processor = UVR5Processor()
        
        # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
        model_info = processor.get_model_info()
        print("ğŸ“‹ æ¨¡å‹è³‡è¨Š:")
        for key, value in model_info.items():
            print(f"  {key}: {value}")
        
        if not model_info['model_exists']:
            print("\nâŒ UVR5 æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨")
            print("è«‹å°‡æ¨¡å‹æª”æ¡ˆæ”¾ç½®åˆ° models/uvr5/ ç›®éŒ„")
            return False
        
        print("\nâœ… UVR5 è™•ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        print("ğŸ’¡ ä½¿ç”¨æ–¹å¼:")
        print("  processor.enhance_audio('input.wav')  # å–®æª”è™•ç†")
        print("  processor.batch_enhance('audio_dir')  # æ‰¹é‡è™•ç†")
        print("  processor.enhance_split_dataset('data/split_dataset')  # è™•ç†åˆ‡åˆ†è³‡æ–™é›†")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False
    
    finally:
        if 'processor' in locals():
            processor.cleanup()


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)