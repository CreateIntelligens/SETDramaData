#!/usr/bin/env python3
"""
HuggingFace æ¨¡å‹é›¢ç·šä¸‹è¼‰è…³æœ¬
- è®€å– .env ä¸­çš„ token
- åœ¨æ–°é€²ç¨‹ä¸­ä¸‹è¼‰ï¼Œé¿å…ç’°å¢ƒè®Šæ•¸è¡çª
- å»ºç«‹å®Œæ•´çš„é›¢ç·šå¿«å–çµæ§‹
"""

import os
import sys
import subprocess
from pathlib import Path
import yaml

def load_env_token():
    """å¾ .env æª”æ¡ˆè¼‰å…¥ HuggingFace token"""
    env_file = Path(__file__).parent.parent / ".env"
    
    if env_file.exists():
        with open(env_file, 'r') as f:
            for line in f:
                line = line.strip()
                if line.startswith('HUGGINGFACE_TOKEN=') or line.startswith('HF_TOKEN='):
                    token = line.split('=', 1)[1].strip().strip('"\'')
                    if token:
                        print(f"âœ… æ‰¾åˆ° HuggingFace token")
                        return token
    
    print("âš ï¸ æœªæ‰¾åˆ° HuggingFace tokenï¼Œå°‡å˜—è©¦åŒ¿åä¸‹è¼‰")
    return None

def create_download_script(cache_dir, token):
    """å»ºç«‹ç¨ç«‹çš„ä¸‹è¼‰è…³æœ¬"""
    script_content = f'''#!/usr/bin/env python3
import os
from pathlib import Path
from huggingface_hub import snapshot_download, login

# æ¸…é™¤æ‰€æœ‰å¯èƒ½çš„é›¢ç·šæ¨¡å¼ç’°å¢ƒè®Šæ•¸
for var in list(os.environ.keys()):
    if 'OFFLINE' in var or 'HF_' in var:
        del os.environ[var]

# å¼·åˆ¶è¨­å®šç·šä¸Šæ¨¡å¼
os.environ['HF_HUB_OFFLINE'] = '0'
os.environ['TRANSFORMERS_OFFLINE'] = '0'

cache_dir = Path("{cache_dir}")
cache_dir.mkdir(parents=True, exist_ok=True)

# ç™»å…¥
token = "{token}"
if token and token != "None":
    try:
        login(token=token)
        print("âœ… HuggingFace ç™»å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸ ç™»å…¥å¤±æ•—: {{e}}")

# ä¸‹è¼‰æ¨¡å‹
models = [
    "pyannote/speaker-diarization-3.1",
    "pyannote/segmentation-3.0", 
    "pyannote/wespeaker-voxceleb-resnet34-LM"
]

success_count = 0
for model_id in models:
    print(f"â¬‡ï¸ ä¸‹è¼‰ {{model_id}}...")
    try:
        snapshot_download(
            model_id,
            cache_dir=str(cache_dir),
            local_files_only=False,
            token=token if token != "None" else None
        )
        print(f"âœ… {{model_id}} ä¸‹è¼‰å®Œæˆ")
        success_count += 1
    except Exception as e:
        print(f"âŒ {{model_id}} ä¸‹è¼‰å¤±æ•—: {{e}}")

print(f"ğŸ“Š ä¸‹è¼‰çµæœ: {{success_count}}/{{len(models)}} å€‹æ¨¡å‹æˆåŠŸ")
'''
    
    script_path = Path(__file__).parent.parent / "temp_download.py"
    with open(script_path, 'w') as f:
        f.write(script_content)
    
    return script_path

def create_config_files(cache_dir):
    """å»ºç«‹å¿…è¦çš„é…ç½®æª”æ¡ˆ"""
    
    # speaker-diarization-3.1 é…ç½®
    diar_config = {
        "pipeline": {
            "_target_": "pyannote.audio.pipelines.SpeakerDiarization",
            "segmentation": "pyannote/segmentation-3.0",
            "embedding": "pyannote/wespeaker-voxceleb-resnet34-LM",
            "clustering": "AgglomerativeClustering",
            "params": {
                "segmentation": {
                    "min_duration_off": 0.0,
                    "onset": 0.5,
                    "offset": 0.5
                },
                "clustering": {
                    "method": "centroid",
                    "min_cluster_size": 12,
                    "threshold": 0.7045654963945799
                }
            }
        }
    }
    
    # segmentation-3.0 é…ç½®
    seg_config = {
        "architecture": {
            "_target_": "pyannote.audio.models.segmentation.PyanNet",
            "sample_rate": 16000,
            "num_channels": 1,
            "sincnet": {
                "stride": [5, 1, 1, 1, 1, 1, 1]
            },
            "tdnn": {
                "context": [0, 1, 2, 3, 4]
            }
        },
        "task": {
            "_target_": "pyannote.audio.tasks.Segmentation",
            "duration": 2.0,
            "warm_up": [0.1, 0.1],
            "balance": "weighted",
            "weight": "balanced"
        }
    }
    
    # æª¢æŸ¥ä¸¦å»ºç«‹é…ç½®æª”æ¡ˆ
    configs_to_create = [
        {
            "path": "models--pyannote--speaker-diarization-3.1",
            "config": diar_config
        },
        {
            "path": "models--pyannote--segmentation-3.0", 
            "config": seg_config
        }
    ]
    
    for item in configs_to_create:
        model_dir = cache_dir / item["path"]
        if model_dir.exists():
            # æ‰¾åˆ° snapshots ç›®éŒ„
            snapshots_dir = model_dir / "snapshots"
            if snapshots_dir.exists():
                for snapshot in snapshots_dir.iterdir():
                    if snapshot.is_dir():
                        config_file = snapshot / "config.yaml"
                        if not config_file.exists():
                            with open(config_file, 'w') as f:
                                yaml.dump(item["config"], f, default_flow_style=False)
                            print(f"   âœ… å»ºç«‹ {item['path']}/config.yaml")

def download_models():
    """ä¸‹è¼‰ pyannote æ¨¡å‹"""
    
    print("ğŸ”§ ä½¿ç”¨ç¨ç«‹é€²ç¨‹ä¸‹è¼‰æ¨¡å‹ï¼ˆé¿å…ç’°å¢ƒè®Šæ•¸è¡çªï¼‰...")
    
    # è¨­å®šä¸‹è¼‰ç›®éŒ„
    project_root = Path(__file__).parent.parent
    cache_dir = project_root / "models" / "huggingface"
    
    print(f"ğŸš€ é–‹å§‹ä¸‹è¼‰ pyannote æ¨¡å‹")
    print(f"ğŸ“ ä¸‹è¼‰ç›®éŒ„: {cache_dir}")
    
    # å»ºç«‹ç›®éŒ„
    cache_dir.mkdir(parents=True, exist_ok=True)
    
    # è¼‰å…¥ token
    token = load_env_token()
    
    # å»ºç«‹ç¨ç«‹çš„ä¸‹è¼‰è…³æœ¬
    script_path = create_download_script(cache_dir, token or "None")
    
    try:
        # åœ¨æ–°é€²ç¨‹ä¸­åŸ·è¡Œä¸‹è¼‰ï¼Œå®Œå…¨éš”é›¢ç’°å¢ƒè®Šæ•¸
        print("ğŸš€ åœ¨ç¨ç«‹é€²ç¨‹ä¸­åŸ·è¡Œä¸‹è¼‰...")
        result = subprocess.run([
            sys.executable, str(script_path)
        ], capture_output=True, text=True, env={})
        
        print(result.stdout)
        if result.stderr:
            print("éŒ¯èª¤è¼¸å‡º:", result.stderr)
        
        if result.returncode == 0:
            print("âœ… ä¸‹è¼‰é€²ç¨‹åŸ·è¡ŒæˆåŠŸ")
        else:
            print(f"âŒ ä¸‹è¼‰é€²ç¨‹å¤±æ•—ï¼Œè¿”å›ç¢¼: {result.returncode}")
            
    except Exception as e:
        print(f"âŒ åŸ·è¡Œä¸‹è¼‰è…³æœ¬å¤±æ•—: {e}")
    
    finally:
        # æ¸…ç†è‡¨æ™‚è…³æœ¬
        if script_path.exists():
            script_path.unlink()
    
    # å»ºç«‹é…ç½®æª”æ¡ˆ
    print(f"\nğŸ”§ å»ºç«‹é…ç½®æª”æ¡ˆ...")
    create_config_files(cache_dir)
    
    # æª¢æŸ¥ä¸‹è¼‰çµæœ
    print(f"\nğŸ” æª¢æŸ¥ä¸‹è¼‰çµæœ...")
    model_count = 0
    for model_dir in cache_dir.glob("models--pyannote--*"):
        if model_dir.is_dir() and any(model_dir.rglob("*.bin")):
            model_count += 1
            print(f"  âœ… {model_dir.name}")
    
    if model_count == 0:
        print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•ä¸‹è¼‰çš„æ¨¡å‹")
        return False
    
    print(f"ğŸ“Š æˆåŠŸä¸‹è¼‰ {model_count} å€‹æ¨¡å‹")
    
    # æ¸¬è©¦é›¢ç·šè¼‰å…¥
    print(f"\nğŸš€ æ¸¬è©¦é›¢ç·šè¼‰å…¥...")
    
    # è¨­å®šé›¢ç·šæ¨¡å¼ç’°å¢ƒè®Šæ•¸
    test_env = os.environ.copy()
    test_env.update({
        'HF_HUB_CACHE': str(cache_dir),
        'HF_HUB_OFFLINE': '1'
    })
    
    try:
        # åœ¨æ–°é€²ç¨‹ä¸­æ¸¬è©¦è¼‰å…¥
        test_script = f'''
import os
os.environ['HF_HUB_CACHE'] = '{cache_dir}'
os.environ['HF_HUB_OFFLINE'] = '1'
from pyannote.audio import Pipeline
pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1")
print("âœ… é›¢ç·šè¼‰å…¥æ¸¬è©¦æˆåŠŸï¼")
'''
        
        result = subprocess.run([
            sys.executable, '-c', test_script
        ], capture_output=True, text=True, env=test_env)
        
        if result.returncode == 0:
            print("âœ… é›¢ç·šè¼‰å…¥æ¸¬è©¦æˆåŠŸï¼")
        else:
            print(f"âŒ é›¢ç·šè¼‰å…¥æ¸¬è©¦å¤±æ•—: {result.stderr}")
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦è¼‰å…¥å¤±æ•—: {e}")
    
    print(f"\nğŸ‰ ä¸‹è¼‰å®Œæˆï¼")
    print(f"ğŸ“ å¿«å–ä½ç½®: {cache_dir}")
    print(f"ğŸ¯ ç³»çµ±å·²æº–å‚™å¥½é›¢ç·šæ¨¡å¼")
    
    return True

if __name__ == "__main__":
    download_models()
