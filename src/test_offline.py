#!/usr/bin/env python3
"""
å®Œå…¨é›¢ç·šæ¨¡å‹æ¸¬è©¦è…³æœ¬ï¼ˆæœ€çµ‚ç‰ˆ - å…¨æ‰‹å‹•ï¼‰
"""
import os
from pathlib import Path
import torch
import yaml
from pyannote.audio.pipelines import SpeakerDiarization
from pyannote.audio.models.segmentation import PyanNet
from pyannote.audio.models.embedding import WeSpeakerResNet34
from pyannote.audio.tasks import SpeakerDiarization as SpeakerDiarizationTask

class DummyProtocol:
    def __init__(self):
        self.preprocessors = {}
        self.scope = "file"  # å¿…éœ€çš„ scope å±¬æ€§
    
    @property
    def name(self):
        return "dummy"
    
    def train(self):
        # è‡³å°‘è¦æœ‰ä¸€å€‹å…ƒç´ ï¼Œé¿å… StopIteration
        yield {"uri": "dummy", "audio": "dummy.wav"}
    
    def development(self):
        yield {"uri": "dummy", "audio": "dummy.wav"}
    
    def test(self):
        yield {"uri": "dummy", "audio": "dummy.wav"}

def load_model_manually(model_class, config_path, checkpoint_path, device="cpu", attach_task=False):
    """
    ä¸€å€‹è¼”åŠ©å‡½æ•¸ï¼Œç”¨æ–¼æ‰‹å‹•å¯¦ä¾‹åŒ–æ¨¡å‹ã€è¼‰å…¥æ¬Šé‡ï¼Œä¸¦å¯é¸æ“‡æ€§åœ°é™„åŠ ä»»å‹™ã€‚
    """
    print(f"   - æ­£åœ¨æ‰‹å‹•è¼‰å…¥ {model_class.__name__}...")
    
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    model_params = config.get('model', {})
    model_params.pop('_target_', None)
    
    model = model_class(**model_params)
    
    if attach_task:
        if 'task' in config:
            # ç›´æ¥æ‰‹å‹•å»ºç«‹ task ç‰©ä»¶ï¼Œä¸é€é config
            from pyannote.audio.core.task import Specifications
            from pyannote.core import SlidingWindow
            
            # å»ºç«‹å‡çš„ specifications
            duration = 10.0
            step = 0.01  # 10ms step
            window = SlidingWindow(duration=duration, step=step)
            specifications = Specifications(
                problem="multilabel_classification",
                resolution=window,
                duration=duration,
                classes=["speaker", "non_speaker"],
                permutation_invariant=True
            )
            
            # ç›´æ¥è¨­å®š model çš„ specificationsï¼Œä¸é€é Task
            model._specifications = specifications
    
    # PyTorch 2.6+ é è¨­ weights_only=Trueï¼Œé€™è£¡å¼·åˆ¶è¨­ç‚º False ä»¥æ”¯æ´èˆŠ checkpoint
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    model.load_state_dict(checkpoint['state_dict'], strict=False)
    
    model.to(device)
    model.eval()
    print(f"     âœ… {model_class.__name__} è¼‰å…¥æˆåŠŸã€‚")
    return model

def test_offline_diarization_fully_manual():
    """
    æ¸¬è©¦å®Œå…¨é›¢ç·šçš„ Speaker Diarization Pipeline è¼‰å…¥ã€‚
    æ¡ç”¨æœ€åº•å±¤ã€æœ€å¯é çš„å…¨æ‰‹å‹•è¼‰å…¥æ–¹å¼ã€‚
    """
    print("="*50)
    print("ğŸš€ é–‹å§‹é€²è¡Œ Pyannote Audio é›¢ç·šè¼‰å…¥æ¸¬è©¦ (å…¨æ‰‹å‹•æ¨¡å¼) ğŸš€")
    print("="*50)

    script_dir = Path(__file__).parent.parent
    base_model_path = script_dir / "models" / "direct"
    
    seg_dir = base_model_path / "segmentation-3.0"
    emb_dir = base_model_path / "wespeaker-voxceleb-resnet34-LM"

    print("\nğŸ¤– 1. æ¸¬è©¦ PyTorch...")
    try:
        print(f"   âœ… PyTorch ç‰ˆæœ¬: {torch.__version__}")
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"   âœ… ä½¿ç”¨è£ç½®: {device.type.upper()}")
    except Exception as e:
        print(f"   âŒ PyTorch æ¸¬è©¦å¤±æ•—: {e}")
        return

    print("\nğŸ”§ 2. æ‰‹å‹•è¼‰å…¥å­æ¨¡å‹...")
    try:
        # ğŸ”¥ ç‚º Segmentation æ¨¡å‹è¼‰å…¥ï¼ˆä¸é™„åŠ  Taskï¼‰
        segmentation_model = load_model_manually(
            PyanNet,
            seg_dir / "config.yaml",
            seg_dir / "pytorch_model.bin",
            device,
            attach_task=True
        )
        
        # ğŸ”¥ ç‚º Embedding æ¨¡å‹è¼‰å…¥
        embedding_model = load_model_manually(
            WeSpeakerResNet34,
            emb_dir / "config.yaml",
            emb_dir / "pytorch_model.bin",
            device
        )
        
    except Exception as e:
        print(f"   âŒ è¼‰å…¥å­æ¨¡å‹å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return

    # 3. å°‡é è¼‰å…¥çš„æ¨¡å‹æ³¨å…¥ Pipeline
    print("\nğŸ”„ 3. å°‡å­æ¨¡å‹æ³¨å…¥ SpeakerDiarization Pipeline...")
    try:
        # æ ¸å¿ƒæ­¥é©Ÿï¼šå°‡æ¨¡å‹ç‰©ä»¶ç›´æ¥å‚³å…¥å»ºæ§‹å­
        pipeline = SpeakerDiarization(
            segmentation=segmentation_model,
            embedding=embedding_model,
        )
        pipeline.to(device)
        print("   âœ… Pipeline å¯¦ä¾‹åŒ–ä¸¦æ³¨å…¥æ¨¡å‹æˆåŠŸï¼")

    except Exception as e:
        print(f"   âŒ Pipeline å¯¦ä¾‹åŒ–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return

    print("\nğŸ‰ğŸ‰ğŸ‰ æ­å–œï¼æ‰€æœ‰æ¸¬è©¦é€šéï¼ŒPyannote Pipeline å·²åœ¨å®Œå…¨é›¢ç·šæ¨¡å¼ä¸‹æˆåŠŸå»ºç«‹ï¼ ğŸ‰ğŸ‰ğŸ‰")
    print("="*50)


if __name__ == "__main__":
    test_offline_diarization_fully_manual()
