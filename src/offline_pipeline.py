#!/usr/bin/env python3
"""
Pyannote.audio æ­£è¦é›¢ç·šè¼‰å…¥æ¨¡çµ„
ä½¿ç”¨å®˜æ–¹æ¨è–¦çš„é›¢ç·šéƒ¨ç½²æ–¹æ³•
"""

import os
import sys
from pathlib import Path
import traceback
import warnings

# éœéŸ³è­¦å‘Š
warnings.filterwarnings("ignore")

class OfflinePipelineLoader:
    """æ­£è¦çš„é›¢ç·š Pipeline è¼‰å…¥å™¨"""
    
    def __init__(self, project_root=None):
        if project_root is None:
            self.project_root = Path(__file__).parent.parent
        else:
            self.project_root = Path(project_root)
        
        self.models_dir = self.project_root / "models"
        self.config_path = self.models_dir / "config.yaml"
        
        # è¨­å®šé›¢ç·šç’°å¢ƒè®Šæ•¸
        self._set_offline_environment()
    
    def _set_offline_environment(self):
        """è¨­å®šå®Œå…¨é›¢ç·šç’°å¢ƒè®Šæ•¸"""
        offline_vars = {
            'HF_HUB_OFFLINE': '1',
            'TRANSFORMERS_OFFLINE': '1',
            'HF_HUB_DISABLE_IMPLICIT_TOKEN': '1',
            'HF_HUB_DISABLE_TELEMETRY': '1',
            'HF_HUB_DISABLE_SYMLINKS_WARNING': '1',
            'HF_DATASETS_OFFLINE': '1',
            'HF_HUB_DISABLE_PROGRESS_BARS': '1',
            'TRANSFORMERS_VERBOSITY': 'error',
            'TOKENIZERS_PARALLELISM': 'false'
        }
        
        for key, value in offline_vars.items():
            os.environ[key] = value
    
    def verify_model_files(self):
        """é©—è­‰æ‰€éœ€çš„æ¨¡å‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨"""
        required_files = {
            "pyannote_model_segmentation-3.0.bin": "åˆ†å‰²æ¨¡å‹",
            "pyannote_model_wespeaker-voxceleb-resnet34-LM.bin": "åµŒå…¥æ¨¡å‹",
            "config.yaml": "é…ç½®æª”æ¡ˆ"
        }
        
        missing_files = []
        for filename, description in required_files.items():
            filepath = self.models_dir / filename
            if not filepath.exists():
                missing_files.append((filename, description))
        
        return missing_files
    
    def load_pipeline(self):
        """è¼‰å…¥æ­£è¦é›¢ç·š Pipeline"""
        missing_files = self.verify_model_files()
        if missing_files:
            raise FileNotFoundError(f"ç¼ºå°‘å¿…è¦çš„æ¨¡å‹æª”æ¡ˆ: {[f[0] for f in missing_files]}")
        
        print("ğŸ¯ è¼‰å…¥æ­£è¦é›¢ç·š Pipeline...")
        return self._load_pipeline_new_method()
    
    def _load_pipeline_new_method(self):
        """æ­£è¦é›¢ç·šæ–¹å¼ï¼ˆä½¿ç”¨ .bin æª”æ¡ˆå’Œ config.yamlï¼‰"""
        original_cwd = Path.cwd().resolve()
        
        try:
            os.chdir(self.models_dir)
            from pyannote.audio import Pipeline
            pipeline = Pipeline.from_pretrained(str(self.config_path))
            print("âœ… æ­£è¦é›¢ç·š Pipeline è¼‰å…¥æˆåŠŸ")
            return pipeline
        finally:
            os.chdir(original_cwd)
    
    def setup_gpu_if_available(self, pipeline):
        """å¦‚æœæœ‰ GPU å¯ç”¨ï¼Œå°‡ Pipeline ç§»åˆ° GPU"""
        try:
            import torch
            if torch.cuda.is_available():
                device = torch.device("cuda")
                pipeline.to(device)
                return device.type
            else:
                return "cpu"
        except Exception:
            return "cpu"

def load_offline_pipeline(project_root=None):
    """
    ä¾¿åˆ©å‡½æ•¸ï¼šè¼‰å…¥é›¢ç·š Pipeline
    
    Args:
        project_root: å°ˆæ¡ˆæ ¹ç›®éŒ„è·¯å¾‘
        
    Returns:
        tuple: (pipeline, device_type)
    """
    loader = OfflinePipelineLoader(project_root)
    pipeline = loader.load_pipeline()
    device_type = loader.setup_gpu_if_available(pipeline)
    
    return pipeline, device_type

def test_offline_pipeline(project_root=None):
    """æ¸¬è©¦é›¢ç·š Pipeline è¼‰å…¥"""
    print("ğŸ¯ æ¸¬è©¦æ­£è¦é›¢ç·š Pipeline è¼‰å…¥")
    print("=" * 50)
    
    try:
        loader = OfflinePipelineLoader(project_root)
        
        # é©—è­‰æª”æ¡ˆ
        print("ğŸ“ é©—è­‰æ¨¡å‹æª”æ¡ˆ...")
        missing_files = loader.verify_model_files()
        if missing_files:
            print("âŒ ç¼ºå°‘æª”æ¡ˆ:")
            for filename, desc in missing_files:
                print(f"  - {desc}: {filename}")
            return False
        print("âœ… æ‰€æœ‰æª”æ¡ˆå­˜åœ¨")
        
        # è¼‰å…¥ Pipeline
        print("ğŸš€ è¼‰å…¥ Pipeline...")
        pipeline = loader.load_pipeline()
        
        # è¨­å®š GPU
        device_type = loader.setup_gpu_if_available(pipeline)
        print(f"ğŸ® ä½¿ç”¨è¨­å‚™: {device_type.upper()}")
        
        # åŸºæœ¬è³‡è¨Š
        print(f"ğŸ“Š Pipeline é¡å‹: {type(pipeline).__name__}")
        
        print("ğŸ‰ æ¸¬è©¦å®Œæˆ - é›¢ç·š Pipeline å·¥ä½œæ­£å¸¸ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        if "--debug" in sys.argv:
            traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_offline_pipeline()
    sys.exit(0 if success else 1)