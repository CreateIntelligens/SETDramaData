#!/usr/bin/env python3
"""
å®Œå…¨é›¢ç·šæ¨¡å¼æ¸¬è©¦è…³æœ¬
æ¸¬è©¦ä½¿ç”¨çµ•å°è·¯å¾‘è¼‰å…¥ pyannote æ¨¡å‹
"""

import os
import sys
from pathlib import Path

# ğŸ¯ å®Œå…¨é›¢ç·šè¨­å®š - ä½¿ç”¨çµ•å°è·¯å¾‘ï¼Œé¿é–‹ HuggingFace Hub
project_root = Path(__file__).parent
models_dir = project_root / "models" / "huggingface"

# å¼·åˆ¶é›¢ç·šæ¨¡å¼ç’°å¢ƒè®Šæ•¸
os.environ.update({
    'TRANSFORMERS_OFFLINE': '1',
    'HUGGINGFACE_HUB_OFFLINE': '1',
    'HF_HUB_OFFLINE': '1'
})

print(f"ğŸ”§ æ¨¡å‹ç›®éŒ„: {models_dir}")
print(f"ğŸ”§ å®Œå…¨é›¢ç·šæ¨¡å¼: å·²å•Ÿç”¨")

import torch
from pyannote.audio import Pipeline, Model

def fix_huggingface_symlinks():
    """è‡ªå‹•ä¿®å¾© HuggingFace å¿«å–ä¸­æå£çš„ç¬¦è™Ÿé€£çµ"""
    print("ğŸ”§ æª¢æŸ¥ä¸¦ä¿®å¾© HuggingFace ç¬¦è™Ÿé€£çµ...")
    
    # å®šç¾©éœ€è¦ä¿®å¾©çš„ç¬¦è™Ÿé€£çµ
    symlink_fixes = [
        {
            "model": "segmentation-3.0",
            "snapshot": "e66f3d3b9eb0873085418a7b813d3b369bf160bb",
            "file": "pytorch_model.bin",
            "blob": "da85c29829d4002daedd676e012936488234d9255e65e86dfab9bec6b1729298"
        },
        {
            "model": "wespeaker-voxceleb-resnet34-LM", 
            "snapshot": "837717ddb9ff5507820346191109dc79c958d614",
            "file": "pytorch_model.bin",
            "blob": "366edf44f4c80889a3eb7a9d7bdf02c4aede3127f7dd15e274dcdb826b143c56"
        },
        {
            "model": "speaker-diarization-3.1",
            "snapshot": "84fd25912480287da0247647c3d2b4853cb3ee5d",
            "file": "config.yaml",
            "blob": "5402e3ca79b6cfa5b0ec283eed920cafe45ee39b"
        }
    ]
    
    fixed_count = 0
    
    for fix in symlink_fixes:
        model_name = fix["model"]
        snapshot_id = fix["snapshot"]
        file_name = fix["file"]
        blob_id = fix["blob"]
        
        # æ§‹å»ºè·¯å¾‘
        snapshot_dir = models_dir / f"models--pyannote--{model_name}" / "snapshots" / snapshot_id
        target_file_path = snapshot_dir / file_name
        blob_path = models_dir / f"models--pyannote--{model_name}" / "blobs" / blob_id
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦ä¿®å¾©
        needs_fix = False
        
        if not target_file_path.exists():
            needs_fix = True
        elif target_file_path.is_file() and target_file_path.stat().st_size == 0:
            needs_fix = True
        elif target_file_path.is_file() and not target_file_path.is_symlink():
            needs_fix = True
        elif target_file_path.is_symlink():
            try:
                target = target_file_path.readlink()
                expected_target = Path("../../blobs") / blob_id
                if target != expected_target:
                    needs_fix = True
            except Exception:
                needs_fix = True
        
        if needs_fix:
            try:
                # æª¢æŸ¥ blob æª”æ¡ˆæ˜¯å¦å­˜åœ¨
                if not blob_path.exists():
                    print(f"âš ï¸ {model_name}/{file_name}: blob æª”æ¡ˆä¸å­˜åœ¨: {blob_path}")
                    continue
                
                # åˆªé™¤ç¾æœ‰æª”æ¡ˆ
                if target_file_path.exists():
                    target_file_path.unlink()
                
                # å»ºç«‹ç¬¦è™Ÿé€£çµ
                relative_blob_path = Path("../../blobs") / blob_id
                target_file_path.symlink_to(relative_blob_path)
                
                print(f"âœ… {model_name}/{file_name}: ç¬¦è™Ÿé€£çµå·²ä¿®å¾©")
                fixed_count += 1
                
            except Exception as e:
                print(f"âŒ {model_name}/{file_name}: ä¿®å¾©å¤±æ•—: {e}")
                continue
    
    return fixed_count

def test_diarization_pipeline():
    """æ¸¬è©¦ diarization pipeline è¼‰å…¥"""
    print("\n1. æ¸¬è©¦ Diarization Pipeline...")
    
    try:
        # Pipeline ä¸æ”¯æ´ local_files_onlyï¼Œåªä½¿ç”¨ cache_dir
        print(f"ğŸ“ å¿«å–ç›®éŒ„: {models_dir}")
        pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization-3.1",
            cache_dir=str(models_dir),
            use_auth_token=None
        )
        print("âœ… Diarization pipeline è¼‰å…¥æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ Diarization pipeline è¼‰å…¥å¤±æ•—: {e}")
        return False

def test_embedding_model():
    """æ¸¬è©¦ embedding æ¨¡å‹è¼‰å…¥"""
    print("\n2. æ¸¬è©¦ Embedding Model...")
    
    try:
        # ä½¿ç”¨ repo ID + cache_dir + local_files_only çš„æ–¹å¼
        print(f"ğŸ“ å¿«å–ç›®éŒ„: {models_dir}")
        model = Model.from_pretrained(
            "pyannote/wespeaker-voxceleb-resnet34-LM",
            cache_dir=str(models_dir),
            local_files_only=True,
            use_auth_token=None
        )
        print("âœ… Embedding æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ Embedding æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return False

def test_segmentation_model():
    """æ¸¬è©¦ segmentation æ¨¡å‹è¼‰å…¥"""
    print("\n3. æ¸¬è©¦ Segmentation Model...")
    
    try:
        # ä½¿ç”¨ repo ID + cache_dir + local_files_only çš„æ–¹å¼
        print(f"ğŸ“ å¿«å–ç›®éŒ„: {models_dir}")
        model = Model.from_pretrained(
            "pyannote/segmentation-3.0",
            cache_dir=str(models_dir),
            local_files_only=True,
            use_auth_token=None
        )
        print("âœ… Segmentation æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ Segmentation æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return False

def main():
    print("ğŸ§ª å®Œå…¨é›¢ç·šæ¨¡å¼æ¸¬è©¦")
    print("=" * 50)
    
    # æª¢æŸ¥ GPU
    if torch.cuda.is_available():
        print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
    else:
        print("âš ï¸ ä½¿ç”¨ CPU")
    
    # æª¢æŸ¥æ¨¡å‹ç›®éŒ„
    if not models_dir.exists():
        print(f"âŒ æ¨¡å‹ç›®éŒ„ä¸å­˜åœ¨: {models_dir}")
        sys.exit(1)
    
    print(f"âœ… æ¨¡å‹ç›®éŒ„å­˜åœ¨: {models_dir}")
    
    # è‡ªå‹•ä¿®å¾©ç¬¦è™Ÿé€£çµ
    print("\nğŸ”§ æª¢æŸ¥ä¸¦ä¿®å¾©ç¬¦è™Ÿé€£çµ...")
    try:
        fixed_count = fix_huggingface_symlinks()
        if fixed_count > 0:
            print(f"âœ… ä¿®å¾©äº† {fixed_count} å€‹ç¬¦è™Ÿé€£çµ")
        else:
            print("âœ… ç¬¦è™Ÿé€£çµæª¢æŸ¥å®Œæˆ")
    except Exception as e:
        print(f"âš ï¸ ç¬¦è™Ÿé€£çµä¿®å¾©å¤±æ•—: {e}")
    
    # æ¸¬è©¦å„å€‹æ¨¡å‹
    results = []
    results.append(test_diarization_pipeline())
    results.append(test_embedding_model())
    results.append(test_segmentation_model())
    
    # ç¸½çµ
    print("\n" + "=" * 50)
    print("ğŸ“Š æ¸¬è©¦çµæœ")
    print("=" * 50)
    
    success_count = sum(results)
    total_count = len(results)
    
    if success_count == total_count:
        print(f"ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼({success_count}/{total_count})")
        print("âœ… å®Œå…¨é›¢ç·šæ¨¡å¼é‹ä½œæ­£å¸¸")
    else:
        print(f"âš ï¸ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼š{success_count}/{total_count}")
        print("âŒ éœ€è¦æª¢æŸ¥æ¨¡å‹æª”æ¡ˆæˆ–é…ç½®")
    
    return success_count == total_count

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
